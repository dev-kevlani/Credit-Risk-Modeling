{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_rows', None)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"/Users/admin/Downloads/LGD/PD_LGD_EAD_model/loan_data_train.csv\", index_col = 0)\n",
    "X_test = pd.read_csv(\"/Users/admin/Downloads/LGD/PD_LGD_EAD_model/loan_data_test.csv\", index_col = 0)\n",
    "y_train = pd.read_csv(\"/Users/admin/Downloads/LGD/PD_LGD_EAD_model/loan_data_label_train.csv\", index_col = 0)\n",
    "y_test = pd.read_csv(\"/Users/admin/Downloads/LGD/PD_LGD_EAD_model/loan_data_label_test.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the features which you have handled properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cols_to_use(df):\n",
    "        categorical_cols = ['grade_', 'home_ownership', 'verification_status__', 'loan_status_', 'purpose_', 'addr_state_', 'initial_list_status_']\n",
    "        other_cols = categorical_cols + \\\n",
    "        ['earliest_cr_line_weeks_', 'acc_now_delinq_', 'total_acc_', 'pub_rec_', 'open_acc_', 'inq_last_6mths_', 'delinq_2yrs_', 'emp_length_'] + \\\n",
    "        ['emp_length_', 'term_', 'issue_d_', 'int_rate_', 'annual_inc_', 'mths_since_last_delinq_', 'dti_', 'mths_since_last_record_']\n",
    "        cols_list = []\n",
    "        for col in other_cols:\n",
    "                cols_list += ((df.filter(like=col)).columns.values.tolist())\n",
    "        inputs_train = df[cols_list]\n",
    "        a = inputs_train.loc[:, ~inputs_train.columns.str.contains('sub_grade|loan_status|categories|cats')]\n",
    "        a = a.loc[:, ~a.columns.duplicated()]\n",
    "        cols = ['home_ownership', 'home_ownership_ANY', 'home_ownership_NONE', 'home_ownership_OTHER', 'home_ownership_RENT', 'purpose_car',\n",
    "                'purpose_small_business', 'purpose_educational', 'purpose_moving', 'purpose_house',\n",
    "                'purpose_renewable_energy', 'purpose_medical', 'purpose_wedding','purpose_vacation', 'purpose_major_purchase', 'purpose_car',\n",
    "                'addr_state_AK', 'addr_state_AL', 'addr_state_AR', 'addr_state_AZ', 'addr_state_CO', 'addr_state_CT', 'addr_state_DC',\n",
    "        'addr_state_DE', 'addr_state_FL', 'addr_state_GA', 'addr_state_HI',\n",
    "        'addr_state_IA', 'addr_state_ID', 'addr_state_IL', 'addr_state_IN',\n",
    "        'addr_state_KS', 'addr_state_KY', 'addr_state_LA', 'addr_state_MA',\n",
    "        'addr_state_MD', 'addr_state_ME', 'addr_state_MI', 'addr_state_MN',\n",
    "        'addr_state_MO', 'addr_state_MS', 'addr_state_MT', 'addr_state_NC',\n",
    "        'addr_state_NE', 'addr_state_NH', 'addr_state_NJ', 'addr_state_NM',\n",
    "        'addr_state_NV', 'addr_state_OH', 'addr_state_OK',\n",
    "        'addr_state_OR', 'addr_state_PA', 'addr_state_RI', 'addr_state_SC',\n",
    "        'addr_state_SD', 'addr_state_TN', 'addr_state_UT',\n",
    "        'addr_state_VA', 'addr_state_VT', 'addr_state_WA', 'addr_state_WI',\n",
    "        'addr_state_WV', 'addr_state_WY', 'addr_state_ND']\n",
    "\n",
    "        a.drop(columns=cols, inplace=True)\n",
    "        a.drop(columns=['open_acc_6m', 'emp_length_int', 'term_int', 'issue_d_days', 'issue_d_weeks', 'annual_inc_joint', 'dti_joint'], inplace=True)\n",
    "        reference_category = ['grade_G', 'home_ownership:RENT_OTHER_ANY_NONE', 'purpose_worst', 'addr_state_worst',\n",
    "                        'initial_list_status_w', 'earliest_cr_line_weeks_(-2.552, 255.2]', 'total_acc_<9',\n",
    "                        'emp_length_0','term_60', 'open_acc_<4', 'inq_last_6mths_>3', 'issue_d_weeks_>391', 'int_rate_(23.996, 26.06]',\n",
    "                        'annual_inc_<38K', 'dti_(37.991, 39.99]']\n",
    "        a.drop(columns=reference_category, inplace=True)\n",
    "        return df, inputs_train, a, reference_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_train_df, sub_train_df, sub_main_cats_train_df, reference_cats = cols_to_use(X_train)\n",
    "main_test_df, sub_test_df, sub_main_cats_test_df, reference_cats = cols_to_use(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PD MODEL ESTIMATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LogisticRegression(max_iter=1000)\n",
    "reg.fit(sub_main_cats_train_df, np.array(y_train).ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = sub_main_cats_train_df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_table = pd.DataFrame(columns=['Feature names'], data=feature_names)\n",
    "summary_table['Coefficients'] = np.transpose(reg.coef_)\n",
    "summary_table.index = summary_table.index + 1\n",
    "summary_table.loc[0] = ['Intercept', reg.intercept_[0]]\n",
    "summary_table.sort_index(inplace=True)\n",
    "summary_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL LG with P values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train.dtypes)\n",
    "print(sub_main_cats_train_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_main_cats_train_df = sub_main_cats_train_df.apply(lambda x: x.astype(int) if x.dtype=='bool' else x)\n",
    "sub_main_cats_test_df = sub_main_cats_test_df.apply(lambda x: x.astype(int) if x.dtype=='bool' else x)\n",
    "# sub_main_cats_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_main_cats_train_df = sm.add_constant(sub_main_cats_train_df)\n",
    "sub_main_cats_test_df = sm.add_constant(sub_main_cats_test_df)\n",
    "model = sm.Logit(y_train, sub_main_cats_train_df)\n",
    "result = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_table = pd.DataFrame({\n",
    "    'Features': result.params.index,\n",
    "    'Coefficients': result.params.values,\n",
    "    'p_values': result.pvalues.values\n",
    "})\n",
    "summary_table.to_csv(\"PD_model_params.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After Observing the p-values - we remove, open_acc, total_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_main_cats_train_df = sub_main_cats_train_df.loc[:,~sub_main_cats_train_df.columns.str.contains('open_acc|total_acc')]\n",
    "sub_main_cats_test_df = sub_main_cats_test_df.loc[:,~sub_main_cats_test_df.columns.str.contains('open_acc|total_acc')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit the model again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_main_cats_train_df = sm.add_constant(sub_main_cats_train_df)\n",
    "sub_main_cats_test_df = sm.add_constant(sub_main_cats_test_df)\n",
    "model = sm.Logit(y_train, sub_main_cats_train_df)\n",
    "result = model.fit()\n",
    "summary_table = pd.DataFrame({\n",
    "    'Features': result.params.index,\n",
    "    'Coefficients': result.params.values,\n",
    "    'p_values': result.pvalues.values\n",
    "})\n",
    "summary_table.to_csv(\"PD_model_params_inclusive_p_vals.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "predictions_prob = result.predict(sub_main_cats_test_df)  # Predicted probabilities\n",
    "predictions = (predictions_prob > 0.85).astype(int)  # Convert probabilities to binary predictions\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f'Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions_prob.plot\n",
    "report = classification_report(y_test, predictions)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_curve(y_test, predictions_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, tr = roc_curve(y_test, predictions_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc = roc_auc_score(y_test, predictions_prob)\n",
    "auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GINI AND KOLMOGOROV SMIRNOV PERFORMANCE MEASURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = pd.concat([y_test,pd.Series(predictions_prob)], axis=1)\n",
    "y_test.columns = ['actual_class', 'predicted_probabilities']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.sort_values('predicted_probabilities', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = y_test.copy()\n",
    "df_test.reset_index(inplace=True)\n",
    "df_test['cumulative_N_population'] = df_test.index+1\n",
    "df_test['cumulative_N_good'] = df_test['actual_class'].cumsum()\n",
    "df_test['cumulative_N_bad'] = df_test['cumulative_N_population'] - df_test['cumulative_N_good']\n",
    "df_test['cumulative_%_population'] = df_test['cumulative_N_population']/len(df_test)\n",
    "df_test['cumulative_%_good'] = df_test['cumulative_N_good']/df_test['actual_class'].sum()\n",
    "df_test['cumulative_%_bad'] = df_test['cumulative_N_bad']/(len(df_test) - df_test['actual_class'].sum())\n",
    "df_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GINI coef is the cum % pop vs cum % bad\n",
    "GINI = AUROC*2 -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_test['cumulative_%_population'],df_test['cumulative_%_bad'])\n",
    "plt.plot(df_test['cumulative_%_population'], df_test['cumulative_%_population'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KOLMOGOROV basically tells the difference in distb of good vs bad\n",
    "\n",
    "perfect model - \n",
    "K-S=1\n",
    "\n",
    "predicting by chance - \n",
    "K-S=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_test['predicted_probabilities'], df_test['cumulative_%_bad'], color='r')\n",
    "plt.plot(df_test['predicted_probabilities'], df_test['cumulative_%_good'], color='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KS = max(df_test['cumulative_%_bad'] - df_test['cumulative_%_good'])\n",
    "KS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testEnvironment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
